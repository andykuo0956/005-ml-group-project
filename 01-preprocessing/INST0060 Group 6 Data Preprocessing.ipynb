{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0faf17d8",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15bd3719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import category_encoders as ce\n",
    "from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77353112",
   "metadata": {},
   "source": [
    "### 1.1 Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e440adf",
   "metadata": {},
   "source": [
    "#### 1.1.1 Reloading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d95ff21e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>...</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>Unnamed: 83</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119783</td>\n",
       "      <td>50777</td>\n",
       "      <td>118</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79267</td>\n",
       "      <td>46918</td>\n",
       "      <td>118</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>Operating Room / Recovery</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92056</td>\n",
       "      <td>34377</td>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33181</td>\n",
       "      <td>74489</td>\n",
       "      <td>83</td>\n",
       "      <td>67.0</td>\n",
       "      <td>27.56</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>190.5</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neurological</td>\n",
       "      <td>Neurologic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 85 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_id  hospital_id   age    bmi  elective_surgery  \\\n",
       "0         66154       25312          118  68.0  22.73                 0   \n",
       "1        114252       59342           81  77.0  27.42                 0   \n",
       "2        119783       50777          118  25.0  31.95                 0   \n",
       "3         79267       46918          118  81.0  22.64                 1   \n",
       "4         92056       34377           33  19.0    NaN                 0   \n",
       "5         33181       74489           83  67.0  27.56                 0   \n",
       "\n",
       "   ethnicity gender  height           icu_admit_source  ...  \\\n",
       "0  Caucasian      M   180.3                      Floor  ...   \n",
       "1  Caucasian      F   160.0                      Floor  ...   \n",
       "2  Caucasian      F   172.7       Accident & Emergency  ...   \n",
       "3  Caucasian      F   165.1  Operating Room / Recovery  ...   \n",
       "4  Caucasian      M   188.0       Accident & Emergency  ...   \n",
       "5  Caucasian      M   190.5       Accident & Emergency  ...   \n",
       "\n",
       "   diabetes_mellitus hepatic_failure immunosuppression  leukemia  lymphoma  \\\n",
       "0                1.0             0.0               0.0       0.0       0.0   \n",
       "1                1.0             0.0               0.0       0.0       0.0   \n",
       "2                0.0             0.0               0.0       0.0       0.0   \n",
       "3                0.0             0.0               0.0       0.0       0.0   \n",
       "4                0.0             0.0               0.0       0.0       0.0   \n",
       "5                1.0             0.0               0.0       0.0       0.0   \n",
       "\n",
       "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \\\n",
       "0                          0.0                Sepsis       Cardiovascular   \n",
       "1                          0.0           Respiratory          Respiratory   \n",
       "2                          0.0             Metabolic            Metabolic   \n",
       "3                          0.0        Cardiovascular       Cardiovascular   \n",
       "4                          0.0                Trauma               Trauma   \n",
       "5                          0.0          Neurological           Neurologic   \n",
       "\n",
       "   Unnamed: 83  hospital_death  \n",
       "0          NaN               0  \n",
       "1          NaN               0  \n",
       "2          NaN               0  \n",
       "3          NaN               0  \n",
       "4          NaN               0  \n",
       "5          NaN               0  \n",
       "\n",
       "[6 rows x 85 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reloading the dataset and displaying in the desired format\n",
    "master_data = pd.read_csv('../00-dataset/00-raw-dataset/dataset.csv')\n",
    "master_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb10602",
   "metadata": {},
   "source": [
    "#### 1.1.2 Removing duplicate rows and dropping completely empty columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89211db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_data = master_data.drop_duplicates()\n",
    "master_data = master_data.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77d9824",
   "metadata": {},
   "source": [
    "#### 1.1.3 Checking the updated structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621c0783",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encounter_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>hospital_id</th>\n",
       "      <th>age</th>\n",
       "      <th>bmi</th>\n",
       "      <th>elective_surgery</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>icu_admit_source</th>\n",
       "      <th>...</th>\n",
       "      <th>cirrhosis</th>\n",
       "      <th>diabetes_mellitus</th>\n",
       "      <th>hepatic_failure</th>\n",
       "      <th>immunosuppression</th>\n",
       "      <th>leukemia</th>\n",
       "      <th>lymphoma</th>\n",
       "      <th>solid_tumor_with_metastasis</th>\n",
       "      <th>apache_3j_bodysystem</th>\n",
       "      <th>apache_2_bodysystem</th>\n",
       "      <th>hospital_death</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>66154</td>\n",
       "      <td>25312</td>\n",
       "      <td>118</td>\n",
       "      <td>68.0</td>\n",
       "      <td>22.73</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>180.3</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Sepsis</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114252</td>\n",
       "      <td>59342</td>\n",
       "      <td>81</td>\n",
       "      <td>77.0</td>\n",
       "      <td>27.42</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>160.0</td>\n",
       "      <td>Floor</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>Respiratory</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119783</td>\n",
       "      <td>50777</td>\n",
       "      <td>118</td>\n",
       "      <td>25.0</td>\n",
       "      <td>31.95</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>172.7</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>Metabolic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79267</td>\n",
       "      <td>46918</td>\n",
       "      <td>118</td>\n",
       "      <td>81.0</td>\n",
       "      <td>22.64</td>\n",
       "      <td>1</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>F</td>\n",
       "      <td>165.1</td>\n",
       "      <td>Operating Room / Recovery</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>Cardiovascular</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>92056</td>\n",
       "      <td>34377</td>\n",
       "      <td>33</td>\n",
       "      <td>19.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>188.0</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>Trauma</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33181</td>\n",
       "      <td>74489</td>\n",
       "      <td>83</td>\n",
       "      <td>67.0</td>\n",
       "      <td>27.56</td>\n",
       "      <td>0</td>\n",
       "      <td>Caucasian</td>\n",
       "      <td>M</td>\n",
       "      <td>190.5</td>\n",
       "      <td>Accident &amp; Emergency</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Neurological</td>\n",
       "      <td>Neurologic</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 84 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   encounter_id  patient_id  hospital_id   age    bmi  elective_surgery  \\\n",
       "0         66154       25312          118  68.0  22.73                 0   \n",
       "1        114252       59342           81  77.0  27.42                 0   \n",
       "2        119783       50777          118  25.0  31.95                 0   \n",
       "3         79267       46918          118  81.0  22.64                 1   \n",
       "4         92056       34377           33  19.0    NaN                 0   \n",
       "5         33181       74489           83  67.0  27.56                 0   \n",
       "\n",
       "   ethnicity gender  height           icu_admit_source  ...  cirrhosis  \\\n",
       "0  Caucasian      M   180.3                      Floor  ...        0.0   \n",
       "1  Caucasian      F   160.0                      Floor  ...        0.0   \n",
       "2  Caucasian      F   172.7       Accident & Emergency  ...        0.0   \n",
       "3  Caucasian      F   165.1  Operating Room / Recovery  ...        0.0   \n",
       "4  Caucasian      M   188.0       Accident & Emergency  ...        0.0   \n",
       "5  Caucasian      M   190.5       Accident & Emergency  ...        0.0   \n",
       "\n",
       "  diabetes_mellitus hepatic_failure  immunosuppression  leukemia  lymphoma  \\\n",
       "0               1.0             0.0                0.0       0.0       0.0   \n",
       "1               1.0             0.0                0.0       0.0       0.0   \n",
       "2               0.0             0.0                0.0       0.0       0.0   \n",
       "3               0.0             0.0                0.0       0.0       0.0   \n",
       "4               0.0             0.0                0.0       0.0       0.0   \n",
       "5               1.0             0.0                0.0       0.0       0.0   \n",
       "\n",
       "   solid_tumor_with_metastasis  apache_3j_bodysystem  apache_2_bodysystem  \\\n",
       "0                          0.0                Sepsis       Cardiovascular   \n",
       "1                          0.0           Respiratory          Respiratory   \n",
       "2                          0.0             Metabolic            Metabolic   \n",
       "3                          0.0        Cardiovascular       Cardiovascular   \n",
       "4                          0.0                Trauma               Trauma   \n",
       "5                          0.0          Neurological           Neurologic   \n",
       "\n",
       "   hospital_death  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "\n",
       "[6 rows x 84 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac252c8f",
   "metadata": {},
   "source": [
    "### 1.2 Missing Value Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d910a831",
   "metadata": {},
   "source": [
    "#### 1.2.1 Calculate Missing Values and their Percentages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c42472e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Missing Percentage (%)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>d1_potassium_max</th>\n",
       "      <td>d1_potassium_max</td>\n",
       "      <td>9585</td>\n",
       "      <td>10.451081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1_potassium_min</th>\n",
       "      <td>d1_potassium_min</td>\n",
       "      <td>9585</td>\n",
       "      <td>10.451081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1_mbp_noninvasive_max</th>\n",
       "      <td>h1_mbp_noninvasive_max</td>\n",
       "      <td>9084</td>\n",
       "      <td>9.904812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h1_mbp_noninvasive_min</th>\n",
       "      <td>h1_mbp_noninvasive_min</td>\n",
       "      <td>9084</td>\n",
       "      <td>9.904812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>apache_4a_icu_death_prob</th>\n",
       "      <td>apache_4a_icu_death_prob</td>\n",
       "      <td>7947</td>\n",
       "      <td>8.665075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1_sysbp_min</th>\n",
       "      <td>d1_sysbp_min</td>\n",
       "      <td>159</td>\n",
       "      <td>0.173367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1_heartrate_max</th>\n",
       "      <td>d1_heartrate_max</td>\n",
       "      <td>145</td>\n",
       "      <td>0.158102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d1_heartrate_min</th>\n",
       "      <td>d1_heartrate_min</td>\n",
       "      <td>145</td>\n",
       "      <td>0.158102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>icu_admit_source</th>\n",
       "      <td>icu_admit_source</td>\n",
       "      <td>112</td>\n",
       "      <td>0.122120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>gender</td>\n",
       "      <td>25</td>\n",
       "      <td>0.027259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Column  Missing Values  \\\n",
       "d1_potassium_max                  d1_potassium_max            9585   \n",
       "d1_potassium_min                  d1_potassium_min            9585   \n",
       "h1_mbp_noninvasive_max      h1_mbp_noninvasive_max            9084   \n",
       "h1_mbp_noninvasive_min      h1_mbp_noninvasive_min            9084   \n",
       "apache_4a_icu_death_prob  apache_4a_icu_death_prob            7947   \n",
       "...                                            ...             ...   \n",
       "d1_sysbp_min                          d1_sysbp_min             159   \n",
       "d1_heartrate_max                  d1_heartrate_max             145   \n",
       "d1_heartrate_min                  d1_heartrate_min             145   \n",
       "icu_admit_source                  icu_admit_source             112   \n",
       "gender                                      gender              25   \n",
       "\n",
       "                          Missing Percentage (%)  \n",
       "d1_potassium_max                       10.451081  \n",
       "d1_potassium_min                       10.451081  \n",
       "h1_mbp_noninvasive_max                  9.904812  \n",
       "h1_mbp_noninvasive_min                  9.904812  \n",
       "apache_4a_icu_death_prob                8.665075  \n",
       "...                                          ...  \n",
       "d1_sysbp_min                            0.173367  \n",
       "d1_heartrate_max                        0.158102  \n",
       "d1_heartrate_min                        0.158102  \n",
       "icu_admit_source                        0.122120  \n",
       "gender                                  0.027259  \n",
       "\n",
       "[74 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = master_data.isnull().sum()\n",
    "missing_percentage = (missing_values / len(master_data)) * 100\n",
    "\n",
    "# Create a missing data report\n",
    "missing_data_report = pd.DataFrame({\n",
    "    \"Column\": master_data.columns,\n",
    "    \"Missing Values\": missing_values,\n",
    "    \"Missing Percentage (%)\": missing_percentage\n",
    "}).sort_values(by=\"Missing Percentage (%)\", ascending=False)\n",
    "\n",
    "# Display columns with missing values\n",
    "missing_data_report[missing_data_report[\"Missing Values\"] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ca33b6",
   "metadata": {},
   "source": [
    "#### 1.2.2 Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81a63c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 91713 entries, 0 to 91712\n",
      "Data columns (total 84 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   encounter_id                   91713 non-null  int64  \n",
      " 1   patient_id                     91713 non-null  int64  \n",
      " 2   hospital_id                    91713 non-null  int64  \n",
      " 3   age                            91713 non-null  float64\n",
      " 4   bmi                            91713 non-null  float64\n",
      " 5   elective_surgery               91713 non-null  int64  \n",
      " 6   ethnicity                      91713 non-null  object \n",
      " 7   gender                         91713 non-null  object \n",
      " 8   height                         91713 non-null  float64\n",
      " 9   icu_admit_source               91713 non-null  object \n",
      " 10  icu_id                         91713 non-null  int64  \n",
      " 11  icu_stay_type                  91713 non-null  object \n",
      " 12  icu_type                       91713 non-null  object \n",
      " 13  pre_icu_los_days               91713 non-null  float64\n",
      " 14  weight                         91713 non-null  float64\n",
      " 15  apache_2_diagnosis             91713 non-null  float64\n",
      " 16  apache_3j_diagnosis            91713 non-null  float64\n",
      " 17  apache_post_operative          91713 non-null  int64  \n",
      " 18  arf_apache                     91713 non-null  float64\n",
      " 19  gcs_eyes_apache                91713 non-null  float64\n",
      " 20  gcs_motor_apache               91713 non-null  float64\n",
      " 21  gcs_unable_apache              91713 non-null  float64\n",
      " 22  gcs_verbal_apache              91713 non-null  float64\n",
      " 23  heart_rate_apache              91713 non-null  float64\n",
      " 24  intubated_apache               91713 non-null  float64\n",
      " 25  map_apache                     91713 non-null  float64\n",
      " 26  resprate_apache                91713 non-null  float64\n",
      " 27  temp_apache                    91713 non-null  float64\n",
      " 28  ventilated_apache              91713 non-null  float64\n",
      " 29  d1_diasbp_max                  91713 non-null  float64\n",
      " 30  d1_diasbp_min                  91713 non-null  float64\n",
      " 31  d1_diasbp_noninvasive_max      91713 non-null  float64\n",
      " 32  d1_diasbp_noninvasive_min      91713 non-null  float64\n",
      " 33  d1_heartrate_max               91713 non-null  float64\n",
      " 34  d1_heartrate_min               91713 non-null  float64\n",
      " 35  d1_mbp_max                     91713 non-null  float64\n",
      " 36  d1_mbp_min                     91713 non-null  float64\n",
      " 37  d1_mbp_noninvasive_max         91713 non-null  float64\n",
      " 38  d1_mbp_noninvasive_min         91713 non-null  float64\n",
      " 39  d1_resprate_max                91713 non-null  float64\n",
      " 40  d1_resprate_min                91713 non-null  float64\n",
      " 41  d1_spo2_max                    91713 non-null  float64\n",
      " 42  d1_spo2_min                    91713 non-null  float64\n",
      " 43  d1_sysbp_max                   91713 non-null  float64\n",
      " 44  d1_sysbp_min                   91713 non-null  float64\n",
      " 45  d1_sysbp_noninvasive_max       91713 non-null  float64\n",
      " 46  d1_sysbp_noninvasive_min       91713 non-null  float64\n",
      " 47  d1_temp_max                    91713 non-null  float64\n",
      " 48  d1_temp_min                    91713 non-null  float64\n",
      " 49  h1_diasbp_max                  91713 non-null  float64\n",
      " 50  h1_diasbp_min                  91713 non-null  float64\n",
      " 51  h1_diasbp_noninvasive_max      91713 non-null  float64\n",
      " 52  h1_diasbp_noninvasive_min      91713 non-null  float64\n",
      " 53  h1_heartrate_max               91713 non-null  float64\n",
      " 54  h1_heartrate_min               91713 non-null  float64\n",
      " 55  h1_mbp_max                     91713 non-null  float64\n",
      " 56  h1_mbp_min                     91713 non-null  float64\n",
      " 57  h1_mbp_noninvasive_max         91713 non-null  float64\n",
      " 58  h1_mbp_noninvasive_min         91713 non-null  float64\n",
      " 59  h1_resprate_max                91713 non-null  float64\n",
      " 60  h1_resprate_min                91713 non-null  float64\n",
      " 61  h1_spo2_max                    91713 non-null  float64\n",
      " 62  h1_spo2_min                    91713 non-null  float64\n",
      " 63  h1_sysbp_max                   91713 non-null  float64\n",
      " 64  h1_sysbp_min                   91713 non-null  float64\n",
      " 65  h1_sysbp_noninvasive_max       91713 non-null  float64\n",
      " 66  h1_sysbp_noninvasive_min       91713 non-null  float64\n",
      " 67  d1_glucose_max                 91713 non-null  float64\n",
      " 68  d1_glucose_min                 91713 non-null  float64\n",
      " 69  d1_potassium_max               91713 non-null  float64\n",
      " 70  d1_potassium_min               91713 non-null  float64\n",
      " 71  apache_4a_hospital_death_prob  91713 non-null  float64\n",
      " 72  apache_4a_icu_death_prob       91713 non-null  float64\n",
      " 73  aids                           91713 non-null  float64\n",
      " 74  cirrhosis                      91713 non-null  float64\n",
      " 75  diabetes_mellitus              91713 non-null  float64\n",
      " 76  hepatic_failure                91713 non-null  float64\n",
      " 77  immunosuppression              91713 non-null  float64\n",
      " 78  leukemia                       91713 non-null  float64\n",
      " 79  lymphoma                       91713 non-null  float64\n",
      " 80  solid_tumor_with_metastasis    91713 non-null  float64\n",
      " 81  apache_3j_bodysystem           91713 non-null  object \n",
      " 82  apache_2_bodysystem            91713 non-null  object \n",
      " 83  hospital_death                 91713 non-null  int64  \n",
      "dtypes: float64(70), int64(7), object(7)\n",
      "memory usage: 58.8+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, np.int64(0))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Strategy 1: Impute missing values for numeric columns with mean\n",
    "numeric_columns = master_data.select_dtypes(include=[\"float64\", \"int64\"]).columns\n",
    "master_data[numeric_columns] = master_data[numeric_columns].apply(lambda col: col.fillna(col.mean()))\n",
    "\n",
    "# Strategy 2: Impute missing values for categorical columns with mode\n",
    "categorical_columns = master_data.select_dtypes(include=[\"object\"]).columns\n",
    "master_data[categorical_columns] = master_data[categorical_columns].apply(lambda col: col.fillna(col.mode()[0]))\n",
    "\n",
    "# Check for remaining missing values\n",
    "remaining_missing_values = master_data.isnull().sum().sum()\n",
    "\n",
    "# Display the updated dataset structure and check if missing values remain\n",
    "master_data.info(), remaining_missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b3822a",
   "metadata": {},
   "source": [
    "### 1.3 Identifying and removing non-relevant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a0a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-related columns based on domain knowledge\n",
    "non_related_columns = ['encounter_id', 'patient_id', 'hospital_id', 'icu_id']\n",
    "master_data = master_data.drop(columns=non_related_columns, errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56e6469-d40e-4502-ab18-842f5bfa3a1c",
   "metadata": {},
   "source": [
    "### 2.1 Create three sub-sampled datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf353c8-3f82-4822-a84e-07b688b4de2f",
   "metadata": {},
   "source": [
    "#### 2.1.1 Use stratified sampling to keep intial class imbalnce of master dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bc709c5-53d6-48f3-bf7f-cfd224923d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master dataset class distribution (Proportion):\n",
      "hospital_death\n",
      "0    0.913698\n",
      "1    0.086302\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      " Master dataset class absolute count:\n",
      "hospital_death\n",
      "0    83798\n",
      "1     7915\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sampled_data_1 class distribution:\n",
      "hospital_death\n",
      "0    0.913706\n",
      "1    0.086294\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "sampled_data_1 class absolute count:\n",
      "hospital_death\n",
      "0    27932\n",
      "1     2638\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sampled_data_2 class distribution:\n",
      "hospital_death\n",
      "0    0.913706\n",
      "1    0.086294\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "sampled_data_2 class absolute count:\n",
      "hospital_death\n",
      "0    27932\n",
      "1     2638\n",
      "Name: count, dtype: int64\n",
      "\n",
      "sampled_data_3 class distribution:\n",
      "hospital_death\n",
      "0    0.913706\n",
      "1    0.086294\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "sampled_data_3 class absolute count:\n",
      "hospital_death\n",
      "0    27932\n",
      "1     2638\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Identify column with target values for classifcation\n",
    "target_column = 'hospital_death'\n",
    "\n",
    "# Determine distribution and absolute count for each class in the master dataset\n",
    "master_class_distribution = master_data[target_column].value_counts(normalize=True)\n",
    "master_class_count = master_data[target_column].value_counts()\n",
    "print(\"Master dataset class distribution (Proportion):\")\n",
    "print(master_class_distribution)\n",
    "print(\"\\n Master dataset class absolute count:\")\n",
    "print(master_class_count)\n",
    "\n",
    "# Equation to set number of samples in each derived dataset\n",
    "num_samples = len(master_data) // 3\n",
    "\n",
    "# Group data by target class\n",
    "grouped = master_data.groupby(target_column)\n",
    "\n",
    "# Initialise a dictionary to store sampled datasets \n",
    "sampled_datasets = {\n",
    "    'sampled_data_1': pd.DataFrame(),\n",
    "    'sampled_data_2': pd.DataFrame(),\n",
    "    'sampled_data_3': pd.DataFrame()\n",
    "}\n",
    "\n",
    "# Create 3 sub-sampled datasets \n",
    "for i, dataset_name in enumerate(sampled_datasets.keys(), start=1):\n",
    "    sampled_data = pd.DataFrame()\n",
    "    \n",
    "    # Sample data from each class group\n",
    "    # random_state is set to simulate semi-random behaviour for reproducability of experiments\n",
    "    for class_label, group in grouped:\n",
    "        samples_to_take = int(master_class_distribution[class_label] * num_samples)\n",
    "        sampled_class_data = group.sample(n=samples_to_take, random_state=np.random.randint(1000))\n",
    "        sampled_data = pd.concat([sampled_data, sampled_class_data])\n",
    "    \n",
    "    # Shuffle data and reset index to reduce data order bias after concatination\n",
    "    sampled_datasets[dataset_name] = sampled_data.sample(frac=1, random_state=np.random.randint(1000)).reset_index(drop=True)\n",
    "\n",
    "# Assign variables explicitly for easier access later on\n",
    "sampled_data_1 = sampled_datasets['sampled_data_1']\n",
    "sampled_data_2 = sampled_datasets['sampled_data_2']\n",
    "sampled_data_3 = sampled_datasets['sampled_data_3']\n",
    "\n",
    "# Print summaries of each dataset to verify proportion of classes and absolute count of data values\n",
    "for name, data in sampled_datasets.items():\n",
    "    print(f\"\\n{name} class distribution:\")\n",
    "    print(data[target_column].value_counts(normalize=True))\n",
    "    print(f\"\\n{name} class absolute count:\")\n",
    "    print(data[target_column].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2290be32-d553-444c-bc55-a74e21f82915",
   "metadata": {},
   "source": [
    "### 2.2 Create class-imbalanced derived dataset using SMOTE-NC (Nominal Continuous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5875a464-d33b-4e6c-8275-717fe3fb56c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution for derived_data_1 (Minority class ratio: 10%):\n",
      "hospital_death\n",
      "0    0.900016\n",
      "1    0.099984\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for derived_data_1:\n",
      "hospital_death\n",
      "0    27932\n",
      "1     3103\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution for derived_data_2 (Minority class ratio: 30%):\n",
      "hospital_death\n",
      "0    0.700015\n",
      "1    0.299985\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for derived_data_2:\n",
      "hospital_death\n",
      "0    27932\n",
      "1    11970\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution for derived_data_3 (Minority class ratio: 50%):\n",
      "hospital_death\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for derived_data_3:\n",
      "hospital_death\n",
      "1    27932\n",
      "0    27932\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Desired rations for the minority class\n",
    "desired_minority_class_ratios = [0.10, 0.30, 0.50]  \n",
    "\n",
    "# Create empty dictionary for derived datasets\n",
    "derived_datasets = {}\n",
    "\n",
    "for i, (sampled_data, desired_minority_class_ratio) in enumerate(\n",
    "    zip([sampled_data_1, sampled_data_2, sampled_data_3], desired_minority_class_ratios), start=1\n",
    "):\n",
    "    # Step 1: identify categorical columns for sampled datasets\n",
    "    categorical_columns = sampled_data.select_dtypes(include=[\"object\"]).columns.tolist()\n",
    "\n",
    "    # Step 2: apply binary coding for use in SMOTE-NC\n",
    "    binary_encoder = ce.BinaryEncoder(cols=categorical_columns)\n",
    "    encoded_data = binary_encoder.fit_transform(sampled_data)\n",
    "\n",
    "    # Step 3: separate features and target\n",
    "    X = encoded_data.drop(columns=[target_column])\n",
    "    y = encoded_data[target_column]\n",
    "    \n",
    "    # Step 4: define categorical indices after encoding\n",
    "    binary_categorical_indices = [\n",
    "        X.columns.get_loc(col) for col in X.columns if any(col.startswith(cat) for cat in categorical_columns)\n",
    "    ]\n",
    "\n",
    "    # Step 5: define correct sampling strategy for SMOTE-NC to match the desired class ratio\n",
    "    minority_class_count = y.value_counts().get(1, 0)\n",
    "    majority_class_count = y.value_counts().get(0, 0)\n",
    "    correct_sampling_strategy = int(majority_class_count * (desired_minority_class_ratio / (1 - desired_minority_class_ratio)))\n",
    "\n",
    "    # Step 6: apply SMOTE-NC with defined sampling strategy\n",
    "    smote_nc = SMOTENC(\n",
    "        categorical_features=binary_categorical_indices, \n",
    "        sampling_strategy={1: correct_sampling_strategy}, \n",
    "        random_state=42\n",
    "    )\n",
    "    X_resampled, y_resampled = smote_nc.fit_resample(X, y)\n",
    "    \n",
    "    # Step 7: Combine resampled data to create derived datasets\n",
    "    derived_data = pd.concat(\n",
    "        [pd.DataFrame(X_resampled, columns=X.columns), pd.DataFrame(y_resampled, columns=[target_column])], axis=1\n",
    "    )\n",
    "\n",
    "    # Shuffle data and reset index to reduce data order bias after concatination\n",
    "    derived_data = derived_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    \n",
    "    # Step 8: store the derived datasets\n",
    "    derived_datasets[f'derived_data_{i}'] = derived_data\n",
    "\n",
    "    \n",
    "    # Print class distribution and absolute counts for verification\n",
    "    print(f\"\\nClass distribution for derived_data_{i} (Minority class ratio: {int(desired_minority_class_ratio * 100)}%):\")\n",
    "    print(derived_data[target_column].value_counts(normalize=True))\n",
    "    print(f\"\\nClass absolute count for derived_data_{i}:\")\n",
    "    print(derived_data[target_column].value_counts())\n",
    "\n",
    "# Step 9: assign variables for derived datasets\n",
    "derived_data_1 = derived_datasets['derived_data_1']\n",
    "derived_data_2 = derived_datasets['derived_data_2']\n",
    "derived_data_3 = derived_datasets['derived_data_3']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab0d011-0366-4fd2-9406-1ce30dea0ef2",
   "metadata": {},
   "source": [
    "### 2.3 Create Train-Validation-Test split for derived datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "beee4063-1063-40a9-ac31-80245e161deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class distribution for train_data_1:\n",
      "hospital_death\n",
      "0    0.900018\n",
      "1    0.099982\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for train_data_1:\n",
      "hospital_death\n",
      "0    19552\n",
      "1     2172\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution for test_data_1:\n",
      "hospital_death\n",
      "0    0.900011\n",
      "1    0.099989\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for test_data_1:\n",
      "hospital_death\n",
      "0    8380\n",
      "1     931\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution for train_data_2:\n",
      "hospital_death\n",
      "0    0.700011\n",
      "1    0.299989\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for train_data_2:\n",
      "hospital_death\n",
      "0    19552\n",
      "1     8379\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution for test_data_2:\n",
      "hospital_death\n",
      "0    0.700025\n",
      "1    0.299975\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for test_data_2:\n",
      "hospital_death\n",
      "0    8380\n",
      "1    3591\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution for train_data_3:\n",
      "hospital_death\n",
      "0    0.5\n",
      "1    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for train_data_3:\n",
      "hospital_death\n",
      "0    19552\n",
      "1    19552\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Class distribution for test_data_3:\n",
      "hospital_death\n",
      "1    0.5\n",
      "0    0.5\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class absolute count for test_data_3:\n",
      "hospital_death\n",
      "1    8380\n",
      "0    8380\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create dictionaries for the training and test splits\n",
    "train_sets, test_sets = {}, {}\n",
    "\n",
    "# Function to stratify split on each derived dataset\n",
    "def stratified_split(data, target_column, train_ratio=0.7, test_ratio=0.3):\n",
    "    \"\"\"\n",
    "    Splits a dataset into training and test sets while maintaining the same \n",
    "    class distribution as the original dataset using stratified sampling.\n",
    "\n",
    "    Parameters:\n",
    "    - data (DataFrame): The dataset to be split.\n",
    "    - target_column (str): The name of the target column used for stratification.\n",
    "    - train_ratio (float): Proportion of data to include in the Train set (set to 0.7).\n",
    "    - test_ratio (float): Proportion of data to include in the Test set (set to 0.3).\n",
    "\n",
    "    Returns:\n",
    "    - train_data (DataFrame): stratified training set.\n",
    "    - test_data (DataFrame): stratified test set.\n",
    "    \"\"\"\n",
    "    train_data = pd.DataFrame()\n",
    "    test_data = pd.DataFrame()\n",
    "\n",
    "    # Group the data by class and split by class, ensuring no data points are shared between the splits\n",
    "    for class_label, group in data.groupby(target_column):\n",
    "        group = group.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "        train_size = int(train_ratio * len(group))\n",
    "        train_data = pd.concat([train_data, group.iloc[:train_size]])\n",
    "        test_data = pd.concat([test_data, group.iloc[train_size:]])\n",
    "\n",
    "    # Shuffle each set after stratified sampling to reduce data order bias after concatination\n",
    "    return (\n",
    "        train_data.sample(frac=1, random_state=42).reset_index(drop=True),\n",
    "        test_data.sample(frac=1, random_state=42).reset_index(drop=True),\n",
    "    )\n",
    "\n",
    "# Split each derived dataset with stratified split function\n",
    "for i, derived_data in enumerate([derived_data_1, derived_data_2, derived_data_3], start=1):\n",
    "    train_set, test_set = stratified_split(derived_data, target_column)\n",
    "\n",
    "    # Store the splits in dictionaries\n",
    "    train_sets[f'train_data_{i}'] = train_set\n",
    "    test_sets[f'test_data_{i}'] = test_set\n",
    "\n",
    "    # Print class distribution and absolute counts for verification\n",
    "    print(f\"\\nClass distribution for train_data_{i}:\")\n",
    "    print(train_set[target_column].value_counts(normalize=True))\n",
    "    print(f\"\\nClass absolute count for train_data_{i}:\")\n",
    "    print(train_set[target_column].value_counts())\n",
    "\n",
    "    print(f\"\\nClass distribution for test_data_{i}:\")\n",
    "    print(test_set[target_column].value_counts(normalize=True))\n",
    "    print(f\"\\nClass absolute count for test_data_{i}:\")\n",
    "    print(test_set[target_column].value_counts())\n",
    "\n",
    "# Assign variables for derived datasets\n",
    "train_data_1, test_data_1 = train_sets['train_data_1'], test_sets['test_data_1']\n",
    "train_data_2, test_data_2 = train_sets['train_data_2'], test_sets['test_data_2']\n",
    "train_data_3, test_data_3 = train_sets['train_data_3'], test_sets['test_data_3']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba8f521-1796-42e8-a488-0e800ec3273f",
   "metadata": {},
   "source": [
    "### Code to reverse encoding on categorical columns in training, validation and test datasets (delete before submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc6ce1e7-e66c-4b1d-90c1-d5f5c441e40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# decoded_train_data_1 = binary_encoder.inverse_transform(train_data_1)\n",
    "# decoded_validation_data_1 = binary_encoder.inverse_transform(validation_data_1)\n",
    "# decoded_test_data_1 = binary_encoder.inverse_transform(test_data_1)\n",
    "\n",
    "# decoded_train_data_2 = binary_encoder.inverse_transform(train_data_2)\n",
    "# decoded_validation_data_2 = binary_encoder.inverse_transform(validation_data_2)\n",
    "# decoded_test_data_2 = binary_encoder.inverse_transform(test_data_2)\n",
    "\n",
    "# decoded_train_data_3 = binary_encoder.inverse_transform(train_data_3)\n",
    "# decoded_validation_data_3 = binary_encoder.inverse_transform(validation_data_3)\n",
    "# decoded_test_data_3 = binary_encoder.inverse_transform(test_data_3)\n",
    "\n",
    "# # Preview results\n",
    "# print(\"\\nDecoded Train Data 1 Preview:\")\n",
    "# print(train_data_1.head())\n",
    "# print(decoded_train_data_1.head())\n",
    "# train_data_1.to_csv('train_data_1.csv', index=False)\n",
    "# decoded_train_data_1.to_csv('train_data_1_decoded.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae63ec4",
   "metadata": {},
   "source": [
    "### Save into csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93db1bc6-d834-4c3d-9148-a51b56ac10f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframes = {\n",
    "    'train_data_1': train_data_1, 'test_data_1': test_data_1,\n",
    "    'train_data_2': train_data_2, 'test_data_2': test_data_2,\n",
    "    'train_data_3': train_data_3, 'test_data_3': test_data_3,\n",
    "}\n",
    "\n",
    "for name, df in dataframes.items():\n",
    "    df.to_csv(f'{name}.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
